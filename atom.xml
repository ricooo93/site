<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-11-05T16:39:59+11:00</updated><id>http://localhost:4000/</id><title type="html">Beyond the horizon</title><subtitle>Jian's personal blog</subtitle><author><name>Jian Lu</name></author><entry><title type="html">TCP/IP common risks</title><link href="http://localhost:4000/security/2018/10/11/TCP-IP-common-security-risks/" rel="alternate" type="text/html" title="TCP/IP common risks" /><published>2018-10-12T10:31:30+11:00</published><updated>2018-10-12T10:31:30+11:00</updated><id>http://localhost:4000/security/2018/10/11/TCP-IP-common%20security%20risks</id><content type="html" xml:base="http://localhost:4000/security/2018/10/11/TCP-IP-common-security-risks/">&lt;h1 id=&quot;application-layer&quot;&gt;Application Layer&lt;/h1&gt;
&lt;p&gt;vulnerability,stack overflow,virus/trojan..&lt;/p&gt;
&lt;h1 id=&quot;transport-layer&quot;&gt;Transport Layer&lt;/h1&gt;
&lt;p&gt;TCP deception,TCP DoS,UDP DoS,port scan..&lt;/p&gt;
&lt;h1 id=&quot;network-layer&quot;&gt;Network Layer&lt;/h1&gt;
&lt;p&gt;IP spoofing,Smurf Attack,ICMP attack,address scan…&lt;/p&gt;
&lt;h1 id=&quot;datalink-layer&quot;&gt;Datalink Layer&lt;/h1&gt;
&lt;p&gt;MAC deception,MAC flood,ARP deception..&lt;/p&gt;
&lt;h1 id=&quot;physical-layer&quot;&gt;Physical Layer&lt;/h1&gt;
&lt;p&gt;Equipment damage,&lt;/p&gt;</content><author><name>Jian Lu</name></author><category term="TCP/IP" /><summary type="html">Application Layer vulnerability,stack overflow,virus/trojan.. Transport Layer TCP deception,TCP DoS,UDP DoS,port scan.. Network Layer IP spoofing,Smurf Attack,ICMP attack,address scan… Datalink Layer MAC deception,MAC flood,ARP deception.. Physical Layer Equipment damage,</summary></entry><entry><title type="html">Using MongoDB with Python</title><link href="http://localhost:4000/mongodb/cloud/2018/09/02/twitter-analysis-improved/" rel="alternate" type="text/html" title="Using MongoDB with Python" /><published>2018-09-03T09:31:30+10:00</published><updated>2018-09-03T09:31:30+10:00</updated><id>http://localhost:4000/mongodb/cloud/2018/09/02/twitter-analysis-improved</id><content type="html" xml:base="http://localhost:4000/mongodb/cloud/2018/09/02/twitter-analysis-improved/">&lt;h1 id=&quot;why-mongodb&quot;&gt;Why MongoDB?&lt;/h1&gt;
&lt;p&gt;In the cloud project of &lt;a href=&quot;./2018-9-1-twitter-analysis.md&quot;&gt;twitter analysis&lt;/a&gt;, couchDB is used to hold all the data. MongoDB is also a kind of NoSQL database while it provides faster read speeds and performs better when the database is growing rapidly. More comparisons can be seen here in this article (&lt;a href=&quot;https://blog.panoply.io/couchdb-vs-mongodb&quot;&gt;couchdb-vs-mongodb&lt;/a&gt;). Generally speaking, MongoDB is more popular than CouchDB, which is also the main reason why I choose to use MongoDB when I try to containerise the twitter analysis application.&lt;/p&gt;
&lt;h1 id=&quot;connect-to-mongodb&quot;&gt;Connect to MongoDB&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pymongo&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#connect to the database server MongoClient(ip,port), the default number is 27017&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pymongo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MongoClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'localhost'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27017&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;create-a-new-database-named-twitter&quot;&gt;Create a new database named twitter&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;twitter&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;note that at this time the database is still not created. It is created until the first record is inserted.&lt;/p&gt;

&lt;h1 id=&quot;create-a-new-collection-named-tweets&quot;&gt;Create a new collection named tweets&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;same as before, the collection is not created until the first record is inserted&lt;/p&gt;

&lt;h1 id=&quot;insert-a-new-record&quot;&gt;Insert a new record&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;new_record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'jian'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#insert_one() inserts one record into the collections, returns a InsertOneResult object, in which includes the _id field of the record&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_record&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inserted_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#insert_many() method inserts a list of records&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_record&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rico'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result_many&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert_many&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_many&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inserted_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;find-a-record--query&quot;&gt;Find a record &amp;amp; Query&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#find_one() returns the first matched record in the selection&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;one_record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#find() returns all the matched record, empty parameter means select ALL&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;all_records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#the first parameter of the find() method is a query object used to confine the results, the second parameter is used to define which fields should be included in the results, 'field':0(omit) or 1(include). You are not allowed to specify both 0 and 1 values in the same object (except if one of the fields is the _id field). If you specify a field with the value 0, all other fields get the value 1, and vice versa&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#find results with name as rico&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rico'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#find results with name starts with r&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reg_query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'$regex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reg_query_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reg_query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#return only the age field&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;age_only&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({},{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h1 id=&quot;sort-the-result&quot;&gt;Sort the result&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#sort() can be used to sort the result in ascending or descending order. It takes one parameter for field and one parameter for order&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ascending_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;descending_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h1 id=&quot;delete-record&quot;&gt;Delete record&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#delete_one() method behaves just like the find_one() method without the field confining. Same is the delete_many() method&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;deleted_one&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delete_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rico'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;deleted_many&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delete_many&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deleted_many&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deleted_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'documents have been deleted'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;delete-collection&quot;&gt;Delete collection&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#drop() method is used to delete the whole collection. The difference between drop() and delete_many({}) is that delete_many({}) just clears the whole records, the collection still exists but it is empty, while after drop() the collection does not exist any more.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#this drops the tweets collection,returns true if drop() succeed, false if the collection does not exist&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;update-collection&quot;&gt;Update collection&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#still, update_one() behaves like find_one(), update_many() behaves like find(). But the second parameter is the new values of the record&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'$set'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;26&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_many&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;limit-the-result&quot;&gt;Limit the Result&lt;/h1&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#for operations that return many records, limit() can be used to limit the result&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#only return 3 results&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;three_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;MongoDB is friendly to a traditional RDBMS user. For every level of granularity you can find an equivalent mapping to RDBMS, like collection-&amp;gt;table, record(document)-&amp;gt;row. But it does not offer an official GUI tool for developers, if you want to see the data more intuitively, &lt;a href=&quot;https://robomongo.org/&quot;&gt;Robo 3T&lt;/a&gt; is a good choice.&lt;/p&gt;</content><author><name>Jian Lu</name></author><category term="NoSQL" /><category term="Python" /><summary type="html">Why MongoDB? In the cloud project of twitter analysis, couchDB is used to hold all the data. MongoDB is also a kind of NoSQL database while it provides faster read speeds and performs better when the database is growing rapidly. More comparisons can be seen here in this article (couchdb-vs-mongodb). Generally speaking, MongoDB is more popular than CouchDB, which is also the main reason why I choose to use MongoDB when I try to containerise the twitter analysis application. Connect to MongoDB ```python import pymongo</summary></entry><entry><title type="html">Cloud Project–Twitter Analysis</title><link href="http://localhost:4000/cloud/2018/09/01/twitter-analysis/" rel="alternate" type="text/html" title="Cloud Project--Twitter Analysis" /><published>2018-09-02T09:31:30+10:00</published><updated>2018-09-02T09:31:30+10:00</updated><id>http://localhost:4000/cloud/2018/09/01/twitter-analysis</id><content type="html" xml:base="http://localhost:4000/cloud/2018/09/01/twitter-analysis/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Twitter analysis is the project of COMP90024 Cluster and Cloud Computing. In this project, we are required to develop a twitter harvester to collect the tweets from a certain area within Australia, and then analyze the tweets to find out some insteresting correlations between tweets and general data from &lt;a href=&quot;https://aurin.org.au/&quot;&gt;AURIN(Australian Urban Research Infrastructure Network)&lt;/a&gt;. All the code will be deployed on the Nectar researcch cloud. I am responsible for the whole backend development and deployment of the system. Source code can be found here on &lt;a href=&quot;https://github.com/betadecay1993/Team54_asignment2&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;requirements&quot;&gt;Requirements&lt;/h1&gt;
&lt;p&gt;Understanding requirements is crucial for the development of the whole system. In this project, the system should be able to continue working with some errors to ensure the fault tolerence of the harvester, a couchdb cluster is needed to be deployed on multiple instances. There are two kinds of harvesters: one is the realtime harvester, which is used to capture the realtime tweets; the other one is the past harvester, which is used to capture the past tweets. One realtime harvester is enough to deal with all the upcoming tweets in Australia, but there are too many past tweets to dig, it is better to use several harvesters working in parallel to improve the efficiency.&lt;/p&gt;

&lt;h1 id=&quot;system-architechture&quot;&gt;System Architechture&lt;/h1&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/images/sysArc.png&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;The above shows the general architecture of the system. A couchdb cluster consisting of three nodes are deployed on three instances on the cloud. The realtime and historical tweet harvesters can be deployed on any instance. Then the sentiment analysis algorithms are applied on the data to find the correlations. In the end, all the data is delivered to through the frontend page to the reader.
In this project, I used Boto to automate the setting up of cloud instances. After the instances are set up, Ansible scripts are used to automatically deploy the couchdb and the whole system to the instances. Below is the video showing the automated deployment of the system from scratch.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/_9p5duTsvR8?rel=0&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;h1 id=&quot;further-improvement&quot;&gt;Further improvement&lt;/h1&gt;
&lt;h2 id=&quot;code-structure&quot;&gt;Code Structure&lt;/h2&gt;
&lt;p&gt;The code should be organized in a clearer way.&lt;/p&gt;
&lt;h2 id=&quot;ansible-scripts&quot;&gt;Ansible scripts&lt;/h2&gt;
&lt;p&gt;Uploading the files to the server can also be done by ansible scripts.&lt;/p&gt;
&lt;h2 id=&quot;containerisation&quot;&gt;Containerisation&lt;/h2&gt;
&lt;p&gt;Containerisation makes it easier to deploy the whole application.&lt;/p&gt;
&lt;h2 id=&quot;git-branch-issue&quot;&gt;Git branch issue&lt;/h2&gt;
&lt;p&gt;All team members committed to the master branch directly. Instead, each team member should be working on different branches and then merge to the master branch once approved by the team.&lt;/p&gt;</content><author><name>Jian Lu</name></author><category term="DevOps" /><category term="docker" /><category term="ansible" /><category term="couchdb" /><category term="AWS" /><category term="boto" /><summary type="html">Introduction Twitter analysis is the project of COMP90024 Cluster and Cloud Computing. In this project, we are required to develop a twitter harvester to collect the tweets from a certain area within Australia, and then analyze the tweets to find out some insteresting correlations between tweets and general data from AURIN(Australian Urban Research Infrastructure Network). All the code will be deployed on the Nectar researcch cloud. I am responsible for the whole backend development and deployment of the system. Source code can be found here on github. Requirements Understanding requirements is crucial for the development of the whole system. In this project, the system should be able to continue working with some errors to ensure the fault tolerence of the harvester, a couchdb cluster is needed to be deployed on multiple instances. There are two kinds of harvesters: one is the realtime harvester, which is used to capture the realtime tweets; the other one is the past harvester, which is used to capture the past tweets. One realtime harvester is enough to deal with all the upcoming tweets in Australia, but there are too many past tweets to dig, it is better to use several harvesters working in parallel to improve the efficiency.</summary></entry></feed>